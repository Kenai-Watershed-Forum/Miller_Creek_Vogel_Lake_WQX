# Miller Creek Discharge & Flow Rate

### Introduction

Hydrology fieldwork focusing on flow and discharge is being conducted throughout the Miller Creek drainage in Fall 2020 - Spring 2021.

-   Near the mouth of Miller Creek, a discharge measurement station was installed in October 2020. At this site a pressure transducer measures water level, and discharge measurements are collected periodically using a SondeTek FlowTracker Acoustic Doppler Velocimeter. These data, along with staff plate observations, are being used to create a rating discharge curve.

-   An experiment to study stream flow rate in Miller Creek was conducted September 15-17, 2021. A plug of dissolved salt (NaCl) was discharged in to the creek, and the resultant spike in conductivity was observed downstream 0.64 km stream distance.

Raw water quality field data is stored in a Google Sheet that can be viewed at <https://tinyurl.com/kwf-vogel-wqx-data> under the "Discharge Measurements" tab.

Site photos are available through a point-and-click pop-up map at <https://arcg.is/0fqvb0>.

```{r setup_02, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# clear environment
rm(list=ls())

# load packages
library(bookdown)
library(tidyverse)
library(googlesheets4)
library(lubridate)
library(readr)
library(readxl)
library(writexl)
library(hms)
library(plotly)
library(DT)
library(xlsx)
library(leaflet)
library(DT)
library(ggpubr)
library(plotrix)
library(packrat)
library(ggpmisc)

# set plotting themes

## geom_col plots theme
col_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 14))

## geom_points plots theme
points_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 11, face = "bold"),
                   title = element_text(size = 18))

# function to exclude multiple items per column
'%ni%' <- Negate('%in%')

# clarify select function
select <- dplyr::select
```

```{r, include = F}

# recognize sheet title and download
discharge_dat <- read_sheet("https://docs.google.com/spreadsheets/d/1lS9eJ7kX91IlYwSgiEQm-BQqif_7o5E4MzcBmqpwSoI/edit#gid=0", 
                           sheet = "Discharge_Measurements") %>%
  # rename columns
  rename(site = `Site Name`,
         sample_date = `Sample Date`) %>%
  # select needed columns
  select(site,
         sample_date,
         Staff_Plate_Height,
         Q_Discharge_cfs) %>%
  # transform column formats
  transform(Staff_Plate_Height = as.numeric(Staff_Plate_Height),
            Q_Discharge_cfs = as.numeric(Q_Discharge_cfs)) 

  # select miller creek pressure transducer site 1
miller_discharge_dat <- discharge_dat %>%
  filter(site == "Miller Creek Pressure Transducer 1")

# save
write.csv(miller_discharge_dat,"output/discharge_results/csv_miller_creek_discharge.csv", row.names = F)

```

<br>

### Miller Creek Discharge Rating Curve

A discharge station was established in October 2020 near the mouth of Miller Creek, including a staff plate and Orpheus Mini pressure transducer.

Site visits were made opportunistically depending on precipitation throughout Summer/Fall 2021, and once in Spring 2022. At each site visit, the pressure transducer is downloaded and a discharge measurement is collected using a SondeTek Flowtracker Acoustic Doppler Velocimeter. See Figure \@ref(fig:rating-curve1) for the discharge rates and staff plate values observed to date.

A total of seven discharge measurements at the Miller Creek mouth site were made between Fall 2020 and Spring 2022. A curve was fit to the scatter plot of stage height vs. discharge.

```{r rating-curve, eval = F, echo=FALSE, fig.cap="Measurements for Miller Creek Discharge Rating Curve"}

# notes:
# this chunk iset to not evaluate in the report due to technical difficulties:
## a.) the ggpmisc equation annotation functions do not appear to work for plotly visualizations. How to annotate plotly with equations?! ggplot show regression equation
## the curve formula appears to be incorrect
## data are instead organized and made available in a downloadable Excel file


ggplotly(
  p <- miller_discharge_dat %>%
  ggplot(aes(Staff_Plate_Height, Q_Discharge_cfs, label = sample_date)) +
  geom_point() +
  geom_smooth(method = "nls", formula = y ~ a*log(x)+b, se = F) +
  stat_poly_eq(aes(label = after_stat(eq.label))) + 
  ggtitle("Miller Creek\nMeasurements for Discharge Rating Curve")
  )

# show in ggplot static
miller_discharge_dat %>%
  ggplot(aes(Staff_Plate_Height, Q_Discharge_cfs, label = sample_date)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ log(x), se = F) +
  stat_poly_eq(aes(label=paste(..eq.label..,..adj.rr.label.., sep = "~~~")), label.x = 1, geom="label",parse=TRUE) +
  ggtitle("Miller Creek\nMeasurements for Discharge Rating Curve")


```

The rating curve for the outlet of Miller Creek and it's source data may be accessed from the downloadable Excel file below:

```{r, echo = F}
xfun::embed_file("output/discharge_results/miller_creek_discharge.xlsx", name = "Miller Creek Outlet Rating Curve Data")
```

```{r rating-curve1, echo = F}
knitr::include_graphics("output/discharge_results/discharge_rating_curve_20220912/Slide1.jpg")
```

```{r rating-curve2, echo = F}
# next: get relationship between PT data and discharge, then apply this relationship to get continuous discharge data
knitr::include_graphics("output/discharge_results/discharge_rating_curve_20220912/Slide2.jpg")

```

<br>

### Pressure Transducer Data

An Orpheus Mini pressure transducer (PT) was deployed at the mouth of Miller Creek from October 2020 through current day (as of `r Sys.Date()`). Values were logged at 0.25 hr intervals.

We plotted staff plate observations with their simultaneous pressure transducer records and fit a linear regression. The resulting relationship (XXXXX, where y is PT value and x is stream discharge) can be used to translate the pressure transducer time series into a stream discharge time series, also known as a flow hydrograph (\@ref(fig:rating-curve2) following the basic approach outlined in [Covino et al. 2020.](https://openecodatalab.github.io/Hydrology-Online/hydrology/7_rating_curve/7_rating_curve.html)

Notes on data inputs to the flow hydrograph for Miller Creek:

1.  The quantity of paired discharge measurements and staff plate observations (7) is less than the minimum quantity desired (8) to record a robust relationship.

2.  The linear relationship does not meet assumptions of statistical normality typically applied for such circumstances. Both of these conditions are a result of the remote location of the project site and the challenging logistics required to visit. While additional field observations would create more precise discharge values, the general shape of the flow hydrography would remain unchanged.

3.  Pressure transducer time series data is missing or excised for the following time periods:

    -   5/24/2021 and 6/24/2022 (logger was not deployed due to site stability concerns)

    -   11/28/21 and 12/1/2022 (logger values \< 0.05, equipment likely affected by ice)

```{r, include = F}
# directories by date

## to do: tidy up the file read-in process, what a mess

## 20210524 site visit / download
dir <- "input/pressure_transducer_data/20210524/"
  
# parameter 1
`0001_20201014` <- read_csv(paste0(dir,"0001_20201014.csv"))

# parameter 2
`0002_20201014` <- read_csv(paste0(dir,"0002_20201014.csv"))

# join parameters together
`20201014` <- left_join(`0001_20201014`,`0002_20201014`) %>%
  transform(date = dmy(date))


## 20210624 site visit / download
dir <- "input/pressure_transducer_data/20210624/"

# parameter 1
`0001_20210624` <- read_csv(paste0(dir,"0001_20210624.csv"))

# parameter 2
`0002_20210624` <- read_csv(paste0(dir,"0002_20210624.csv"))

# parameter 3
`0003_20210624` <- read_csv(paste0(dir,"0003_20210624.csv"))

# join parameters together
`20210624` <- left_join(`0001_20210624`,`0002_20210624`) %>%
  left_join(`0003_20210624`) %>%
  transform(date = dmy(date))


## 20220515 site visit / download
dir <- "input/pressure_transducer_data/20220515/"

# parameter 1
`0001_20220515` <- read_csv(paste0(dir,"0001_20220515.csv"))

# parameter 2
`0002_20220515` <- read_csv(paste0(dir,"0002_20220515.csv"))

# parameter 3
`0003_20220515` <- read_csv(paste0(dir,"0003_20220515.csv"))

# join parameters together
`20220515` <- left_join(`0001_20220515`,`0002_20220515`) %>%
  left_join(`0003_20220515`) %>%
  transform(date = dmy(date))

### join all download dates to single dataframe
pt <- bind_rows(`20201014`,`20210624`,`20220515`) %>%
  # format time to hms
  mutate(foo = as_hms(paste0(time,":00"))) %>%
  select(-time) %>%
  rename(time = foo) %>%
  # create datetime column
  mutate(datetime = ymd_hms(paste(date, time))) %>%
  # make parameter values numeric
  transform(parameter1 = as.numeric(parameter1),
            parameter2 = as.numeric(parameter2),
            parameter3 = as.numeric(parameter3)) %>%
  # make long format
  pivot_longer(cols = contains("parameter"),
               names_to = "param",
               values_to = "val") %>%
  # eliminate duplicate observations
  distinct() %>%
  #filter(!is.na(val)) %>%
  # remove "parameter3", which is not applicable
  filter(param != "parameter3")
  

```

<br>

```{r, echo = F}
# plot raw pt time series

# remove erroneous data late november 2021
pt_remove <- pt %>%
  filter(param == "parameter1") %>%
  filter(between(date,as.Date("2021-11-28"),as.Date("2021-12-01"))) %>%
  select(date)
pt <- anti_join(pt,pt_remove)

# need to make this an anti_join table

  
# plot
#pt %>%
#  ggplot(aes(datetime,val)) +
#  geom_line(na.rm = F)




p <- pt %>%
#   create hourly average values to smooth visualization
    group_by(datetime_round = floor_date(datetime,"day")) %>%
    summarise(mean_val = mean(val), na.rm = T) %>%
  # plot
  ggplot(aes(datetime_round,mean_val)) +
  geom_path(na.rm = F)
p
ggplotly(p)
```


```{r}

 
p <- pt %>%
  filter(param == "parameter1") %>%
    # remove negative values
  #filter(val >= -0.5 ) %>%
    # rescale PT observations between zero and 1
#  mutate(val_sc = rescale(val, to = c(0,1))) %>%

    # apply conversion from PT values to discharge values
    mutate(Q = 53.437*val^.5179) %>%
  
      # create hourly average values to smooth visualization
    group_by(datetime_round = floor_date(datetime,"day")) %>%
    summarise(mean_Q = mean(Q)) %>%
  
  ggplot(aes(datetime_round,mean_Q)) +
  geom_path() 
 
ggplotly(p)


# to do : use anti_join method to excise non-instream data from plot


# y = 0.0122x - 0.0592
# x = (y + 0.0592)/0.0122
# resultant discharge values are an order of magnitude past realistic.

# new
# Q = 53.457pt^0.5179
```

<br>

### Discharge measurements at other sites

Additional discharge measurements were taken throughout Summer 2021 at two additional sites near Vogel Lake, near the outlets of Kuguyuk Pond and Bird Pond. See Figure \@ref(fig:other-discharge) for discharge values observed to date.

```{r other-discharge, echo=FALSE, fig.cap="Other discharge measurements"}
#plot 
ggplotly(
  p <- discharge_dat %>%
  filter(site %in% c("Bird Pond Discharge Site", 
                     "Kuguyuk Pond Discharge Site")) %>%
    ggplot(aes(as.factor(sample_date),Q_Discharge_cfs)) +
    geom_point() +
    facet_grid(. ~ site) +
    xlab("") +
    ylab("Stream Discharge Rate (cfs)") +
    ggtitle("Additional Discharge Measurement Sites")
)


```

<br>

### Stream Flow Rate Experiment

On September 15-17, 2021 we conducted an experiment to examine stream flow rate in Miller Creek. We measured downstream transport time of dissolved solutes by deploying a plug of dissolved salt and measuring a resultant change in conductivity at a site downstream.

##### Methods

We deployed a plug of dissolved salt into the Miller Creek stream channel and measured conductivity continuously at a downstream site. See Figure \@ref(fig:nacl-map) for salt deployment and conductivity monitoring sites.

<br>

```{r nacl-map, echo = FALSE, fig.cap="Stream Flow Rate Study Area. Stream distance between the NaCl release site and the downstream measurement site is 0.63 km (0.39 mi)."}
knitr::include_graphics('images/stream_flow_rate_sites.png')
```

<br>

The Vogel Lake / Miller Creek system is a low-gradient drainage with little observable flow within 0.5 miles downstream of the lake outlet. We deployed our salt plug downstream from the Vogel Lake outlet at the first site with visibly evident surface flow, which was over the top of the first downstream beaver dam.

We released 140 lbs of dissolved NaCl by dissolving appx 15 lbs at a time in a 35 gallon trash can, then discharging it on the downstream side of the beaver dam into the stream channel. Our downstream site monitoring conductivity was 0.63 km (0.39 mi) downstream center-channel.

To record conductivity we used a pair of simultaneously deployed Hydrolab MS5 Sondes suspended from a floating buoy. We programmed the sondes to record at 0.25 hour intervals. We examined the resultant time series for exposure or errors and removed these data points. We averaged conductivity values between the two Hydrolab units in the final results.

```{r echo = FALSE, message = FALSE}
# read in raw csv files and bind together
hl1 <- read.csv("input/hydrolab_data/nacl_buoy_site/46005_Miller_NaCl.csv",
                skip = 14) %>%
  select(-X.2,-X.4,-X.6,-X.7) %>%
  mutate(id = 46005)


hl2 <- read.csv("input/hydrolab_data/nacl_buoy_site/64821_Miller_NaCl.csv",
                skip = 14) %>%
  select(-X.2,-X.4) %>%
  mutate(id = 64821)

hl <- bind_rows(hl1,hl2) 
colnames(hl) <- c("date","time","temp_C","cond_uScm","id")

# prep for analysis
hl <- hl %>%
  mutate(datetime = mdy_hms(paste(date,time)))%>%
  # round all times to nearest minute
  mutate(datetime = round_date(datetime, unit = "minute")) %>%
  # average values between two sondes
  group_by(datetime) %>%
  summarise(mean_cond_uScm = mean(cond_uScm))

```

<br>

##### Results

We measured a readily evident rise in conductivity values at the downstream monitoring site. See Figure \@ref(fig:nacl-fig) for the time series of conductivity data.

```{r nacl-fig, echo=FALSE, fig.cap= "Conductivity values at the site downstream of the NaCl release site. The NaCl plug was released at 19:30 on 9/15/2021. The release and measurement site coordinates can be accessed at the ArcGIS Online Map at https://arcg.is/0LqOKH0."}
ggplotly(
  p <- hl %>%
  ggplot(aes(datetime,mean_cond_uScm)) +
  geom_point() +
  ylim(70,140) +
  xlab("Date/Time") +
  ylab("Conductivity (uS/cm)") +
  ggtitle("Conductivity vs. Time\nat site 0.39 mi Downstream From Salt Deployment")
  )

```

In Figure \@ref(fig:nacl-fig) we can observe the following:

-   [Initial NaCl Deployment:]{.underline} 9/15/2021 19:30

-   [Start of the rising limb of the conductivity spike:]{.underline} 9/15/2021 22:00 (2.5 hrs after deployment)

-   [Maximum conductivity peak (\~20% above baseline values):]{.underline} 01:30 9/16/2021 (6.0 hours after deployment)

-   [Return to baseline conductivity levels:]{.underline} 9/16/2021 15:00 (19.5 hrs after deployment)

Based on these results, peak concentration of the dissolved solute traveled though this section of Miller Creek at [**0.11 km/h (0.06 mph)**]{.underline}.
